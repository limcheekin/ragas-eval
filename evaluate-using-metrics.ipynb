{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --no-cache-dir -qU ragas nltk langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/limcheekin/dev/ws/py/ragas-eval/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\n",
    "    \"explodinggradients/amnesty_qa\",\n",
    "    \"english_v3\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "eval_dataset = EvaluationDataset.from_hf_dataset(dataset[\"eval\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, SemanticSimilarity\n",
    "from ragas import evaluate, RunConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup LLM evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatOpenAI doesn't exist as a standalone product or service.  It's likely you're referring to using the OpenAI API, specifically models like `gpt-3.5-turbo` or `gpt-4`, which power conversational AI applications.  These models are accessed through the OpenAI API, not a separate \"ChatOpenAI\" platform.\n",
      "\n",
      "To use OpenAI's conversational AI models, you'll need to:\n",
      "\n",
      "1. **Create an OpenAI Account:**  Go to the OpenAI website (openai.com) and sign up for an account.  You'll likely need to provide payment information, even if you only use the free trial.\n",
      "\n",
      "2. **Obtain an API Key:** Once your account is created, navigate to your account settings to find your API keys.  You'll need this key to authenticate your requests to the OpenAI API.  Keep this key secret; do not share it publicly.\n",
      "\n",
      "3. **Choose a Programming Language and Library:** OpenAI's API can be accessed using various programming languages. Popular choices include Python (with the `openai` library), Node.js, and others.  You'll need to install the appropriate library for your chosen language.  For Python, for example, you would use `pip install openai`.\n",
      "\n",
      "4. **Make API Calls:**  You'll use your API key and the chosen library to send requests to the OpenAI API.  These requests include the prompt (your question or instruction) and other parameters to control the model's response, such as temperature (creativity) and max_tokens (length of response).  The API will return a JSON response containing the model's generated text.\n",
      "\n",
      "5. **Process the Response:** Your code will then need to handle the JSON response, extracting the generated text and potentially other information.\n",
      "\n",
      "**Example (Python):**\n",
      "\n",
      "```python\n",
      "import openai\n",
      "\n",
      "# Set your API key\n",
      "openai.api_key = \"YOUR_API_KEY\"\n",
      "\n",
      "# Define your prompt\n",
      "prompt = \"What is the capital of France?\"\n",
      "\n",
      "# Make the API call\n",
      "response = openai.Completion.create(\n",
      "  engine=\"text-davinci-003\", # Or a more modern model like gpt-3.5-turbo\n",
      "  prompt=prompt,\n",
      "  max_tokens=50,\n",
      "  n=1,\n",
      "  stop=None,\n",
      "  temperature=0.7,\n",
      ")\n",
      "\n",
      "# Extract and print the generated text\n",
      "generated_text = response.choices[0].text.strip()\n",
      "print(generated_text)\n",
      "```\n",
      "\n",
      "Remember to replace `\"YOUR_API_KEY\"` with your actual API key.  Note that `text-davinci-003` is an older model;  consider using `gpt-3.5-turbo` or `gpt-4` for better conversational capabilities, but be aware that these might have different usage costs.  Consult the OpenAI API documentation for the most up-to-date information on models and parameters.\n",
      "\n",
      "This is a simplified example.  For more complex interactions, you'll need to handle error conditions, implement better prompt engineering, and potentially use more advanced features of the API.  The OpenAI documentation is your best resource for learning more.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "llm = ChatOpenAI(model=\"gemini-1.5-flash\", \n",
    "                 timeout=900, \n",
    "                 api_key=\"sk-1\", \n",
    "                 base_url=\"http://localhost:4000/v1\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"How do I use ChatOpenAI?\")\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=\"nomic-embed-text\", \n",
    "                                                                   base_url=\"http://localhost:11434/v1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 60/60 [36:33<00:00, 36.57s/it]\n"
     ]
    }
   ],
   "source": [
    "metrics = [\n",
    "    LLMContextRecall(llm=evaluator_llm), \n",
    "    FactualCorrectness(llm=evaluator_llm), \n",
    "    Faithfulness(llm=evaluator_llm),\n",
    "    # SemanticSimilarity(embeddings=evaluator_embeddings)\n",
    "]\n",
    "\n",
    "results = evaluate(dataset=eval_dataset, metrics=metrics, batch_size=1, \n",
    "                   run_config=RunConfig(timeout=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export and analyzing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>factual_correctness</th>\n",
       "      <th>faithfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the global implications of the USA Su...</td>\n",
       "      <td>[- In 2022, the USA Supreme Court handed down ...</td>\n",
       "      <td>The global implications of the USA Supreme Cou...</td>\n",
       "      <td>The global implications of the USA Supreme Cou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which companies are the main contributors to G...</td>\n",
       "      <td>[In recent years, there has been increasing pr...</td>\n",
       "      <td>According to the Carbon Majors database, the m...</td>\n",
       "      <td>According to the Carbon Majors database, the m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which private companies in the Americas are th...</td>\n",
       "      <td>[The issue of greenhouse gas emissions has bec...</td>\n",
       "      <td>According to the Carbon Majors database, the l...</td>\n",
       "      <td>The largest private companies in the Americas ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What action did Amnesty International urge its...</td>\n",
       "      <td>[In the case of the Ogoni 9, Amnesty Internati...</td>\n",
       "      <td>Amnesty International urged its supporters to ...</td>\n",
       "      <td>Amnesty International urged its supporters to ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the recommendations made by Amnesty I...</td>\n",
       "      <td>[In recent years, Amnesty International has fo...</td>\n",
       "      <td>Amnesty International made several recommendat...</td>\n",
       "      <td>The recommendations made by Amnesty Internatio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What are the global implications of the USA Su...   \n",
       "1  Which companies are the main contributors to G...   \n",
       "2  Which private companies in the Americas are th...   \n",
       "3  What action did Amnesty International urge its...   \n",
       "4  What are the recommendations made by Amnesty I...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [- In 2022, the USA Supreme Court handed down ...   \n",
       "1  [In recent years, there has been increasing pr...   \n",
       "2  [The issue of greenhouse gas emissions has bec...   \n",
       "3  [In the case of the Ogoni 9, Amnesty Internati...   \n",
       "4  [In recent years, Amnesty International has fo...   \n",
       "\n",
       "                                            response  \\\n",
       "0  The global implications of the USA Supreme Cou...   \n",
       "1  According to the Carbon Majors database, the m...   \n",
       "2  According to the Carbon Majors database, the l...   \n",
       "3  Amnesty International urged its supporters to ...   \n",
       "4  Amnesty International made several recommendat...   \n",
       "\n",
       "                                           reference  context_recall  \\\n",
       "0  The global implications of the USA Supreme Cou...             1.0   \n",
       "1  According to the Carbon Majors database, the m...             1.0   \n",
       "2  The largest private companies in the Americas ...             1.0   \n",
       "3  Amnesty International urged its supporters to ...             1.0   \n",
       "4  The recommendations made by Amnesty Internatio...             1.0   \n",
       "\n",
       "   factual_correctness  faithfulness  \n",
       "0                 0.50      0.095238  \n",
       "1                 0.11      0.166667  \n",
       "2                 0.59      0.500000  \n",
       "3                 0.25      0.166667  \n",
       "4                 0.36      0.318182  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = results.to_pandas()\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
